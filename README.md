# Git branch 測試
## &emsp;&emsp;王浩閔
## &emsp;&emsp;許韡瀚
## &emsp;&emsp;葉育綸

---
# [計劃書連結](https://1drv.ms/w/c/f91728052b40ca1c/Eeus_b4zEsVOrjuZkx9ZZFAB6fw6MekU8xJfTSsAPnXh3A?e=E2vqdO)
# 計畫書文案

&emsp;&emsp;近幾年智慧城市的議題一直被談論，但其實「影像定位」常常被大家忽略。在許多的導航、巡檢、交通分析系統當中都依賴著Google Stree View(Google街景) 所提供的龐大環景資料藉此來輔助定位。然而，當我們投入研究、更深入的查資料，就越發覺得背脊發涼—Google並不是我們台灣的企業,而是美國企業，他們並沒有義務永遠的開放資料或者是API(應用程式介面)。  
&emsp;&emsp;因此，研究的核心問題逐漸明確:如何利用CNN，讓模型只靠環景影像，便能夠準確定位空間位置？加入遮罩（遮蔽）後，定位的精準度是否能夠維持？還有在不同的天氣、光線、季節下，模型是否能辨識同一個地點？看看是否可以建立一套完全不依賴 Google的影像定位？這些問題,不只是技術的挑戰，更像是一場「打破依賴、建立自主能力」的冒險。就像故事裡離開庇護的主角，我們想知道：當他人所提供的資源不復存在時，我們是否能夠依靠自己的資料、自己所訓練的模型，找到回家正確的路？ 